# -*- coding: utf-8 -*-
"""workking ai fullmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C4FojJs12QuCgV6BMORHC0u7zdg1eoit
"""

# (Removed Jupyter/Colab magic install lines for compatibility)

# @title Tennis ATP Match-Winner Model ‚Äì v6.2 (Tennis Abstract Compatible)
"""
Tennis ATP Match-Winner Model ‚Äì v6.2 (Tennis Abstract Compatible)
‚Ä¢ Jeff Sackmann match data (2010-2024)
‚Ä¢ Enhanced with activity tracking and form analysis
‚Ä¢ Compatible with Tennis Abstract Elo ratings and player data
‚Ä¢ Strictly pre-match information ‚Üí no data-leakage
‚Ä¢ GPU-accelerated training with CPU fallback
‚Ä¢ Expected accuracy ‚âà 65-67% AUC ‚âà 0.70-0.72
"""

# ‚ïî‚ïê‚ïê 0. Imports & Configuration ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
import os, sys, warnings, pickle, requests
import pandas as pd, numpy as np
from tqdm import tqdm
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, roc_auc_score
import math
from datetime import datetime, timedelta
from collections import defaultdict
import subprocess
warnings.filterwarnings("ignore")

REPO = "https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/"
DATA = "tennis_atp_data"
MIN_YR = 2010

# ‚ïî‚ïê‚ïê 1. Glicko Component Calculations ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
class GlickoComponents:
    """Custom Glicko rating system implementation using core components"""
    
    def __init__(self, initial_rating: float = 1500.0, initial_rd: float = 350.0, 
                 initial_volatility: float = 0.06, c: float = 34.64, tau: float = 0.5):
        """
        Initialize Glicko components.
        
        Args:
            initial_rating: Starting rating (default 1500)
            initial_rd: Starting rating deviation (default 350)
            initial_volatility: Starting volatility (default 0.06)
            c: System constant (default 34.64)
            tau: Volatility constraint (default 0.5)
        """
        self.rating = initial_rating
        self.rd = initial_rd
        self.volatility = initial_volatility
        self.c = c
        self.tau = tau
        self.last_update = None
        
    def update_rd_over_time(self, days_since_last_match: int) -> float:
        """
        Update rating deviation based on time since last match.
        
        Args:
            days_since_last_match: Days since last match
            
        Returns:
            Updated rating deviation
        """
        if days_since_last_match is None:
            return self.rd
            
        # Convert days to years
        years = days_since_last_match / 365.25
        
        # Update RD based on time
        new_rd = min(350, math.sqrt(self.rd**2 + (self.c**2) * years))
        return new_rd
    
    def calculate_expected_score(self, opponent_rating: float, opponent_rd: float) -> float:
        """
        Calculate expected score against an opponent.
        
        Args:
            opponent_rating: Opponent's rating
            opponent_rd: Opponent's rating deviation
            
        Returns:
            Expected score (0-1)
        """
        g = 1 / math.sqrt(1 + 3 * (opponent_rd**2) / (math.pi**2))
        expected = 1 / (1 + 10**(-g * (self.rating - opponent_rating) / 400))
        return expected
    
    def update_after_match(self, opponent_rating: float, opponent_rd: float, 
                          actual_score: float, days_since_last_match: int) -> None:
        """
        Update rating components after a match.
        
        Args:
            opponent_rating: Opponent's rating
            opponent_rd: Opponent's rating deviation
            actual_score: Actual match result (1 for win, 0 for loss)
            days_since_last_match: Days since last match
        """
        # Update RD for time passed
        self.rd = self.update_rd_over_time(days_since_last_match)
        
        # Calculate expected score
        expected = self.calculate_expected_score(opponent_rating, opponent_rd)
        
        # Calculate g and E
        g = 1 / math.sqrt(1 + 3 * (opponent_rd**2) / (math.pi**2))
        E = 1 / (1 + 10**(-g * (self.rating - opponent_rating) / 400))
        
        # Calculate d^2
        d_squared = 1 / (g**2 * E * (1 - E))
        
        # Update rating
        rating_change = g * (actual_score - E) / d_squared
        self.rating += rating_change
        
        # Update RD
        new_rd = math.sqrt(1 / d_squared)
        self.rd = min(350, new_rd)
        
        # Update volatility (simplified)
        if abs(actual_score - E) > 0.5:
            self.volatility = min(0.06, self.volatility * 1.1)
        else:
            self.volatility = max(0.01, self.volatility * 0.95)

def calculate_confidence_weight(rd: float) -> float:
    """
    Convert rating deviation to confidence weight (0-1 scale).
    
    Args:
        rd: Rating deviation
        
    Returns:
        Confidence weight between 0 and 1
    """
    return 1 / (1 + rd / 100)

def calculate_win_probability(r1: float, rd1: float, r2: float, rd2: float) -> float:
    """
    Calculate win probability using Glicko components.
    
    Args:
        r1: Player 1 rating
        rd1: Player 1 rating deviation
        r2: Player 2 rating
        rd2: Player 2 rating deviation
        
    Returns:
        Win probability for player 1
    """
    g = 1 / math.sqrt(1 + 3 * rd2**2 / (math.pi**2))
    expected = 1 / (1 + 10**(-g * (r1 - r2) / 400))
    return expected

def check_gpu_availability() -> bool:
    """Check if GPU is available for XGBoost training"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ GPU detected and available for training")
            return True
        else:
            print("‚ö†Ô∏è  GPU not detected, using CPU")
            return False
    except FileNotFoundError:
        print("‚ö†Ô∏è  nvidia-smi not found, using CPU")
        return False

# ‚ïî‚ïê‚ïê 2. Helper Functions ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def parse_date(x) -> object:
    """Safe date parsing function"""
    if pd.isna(x): 
        return pd.NaT
    s = str(int(x)) if isinstance(x,(int,float)) else str(x)
    for f in ("%Y%m%d","%Y-%m-%d","%d/%m/%Y","%m/%d/%Y"):
        try: 
            return pd.to_datetime(s,format=f)
        except: 
            pass
    return pd.to_datetime(s,errors="coerce")

# ‚ïî‚ïê‚ïê 3. Download Jeff Sackmann match CSVs ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def download_csvs() -> list:
    """Download ATP match CSV files from Jeff Sackmann's repository"""
    os.makedirs(DATA, exist_ok=True)
    existing = [f for f in os.listdir(DATA)
                if f.endswith(".csv") and "matches" in f and "doubles" not in f]
    if existing:
        print(f"‚úÖ Found {len(existing)} existing CSV files")
        return existing

    todo  = [f"atp_matches_{y}.csv"         for y in range(1968,2025)]
    todo += [f"atp_matches_futures_{y}.csv" for y in range(1968,2025)]
    todo += [f"atp_matches_qual_chall_{y}.csv" for y in range(1968,2025)]

    print("üì• Downloading ATP match data...")
    for fn in tqdm(todo, desc="Downloading match CSVs"):
        url = REPO + fn
        try:
            r = requests.get(url, timeout=30)
            if r.ok:
                open(os.path.join(DATA, fn), "wb").write(r.content)
        except Exception as e:
            print(f"Failed to download {fn}: {e}")

    return [f for f in os.listdir(DATA)
            if f.endswith(".csv") and "matches" in f and "doubles" not in f]

# ‚ïî‚ïê‚ïê 4. Process matches ‚Üí pre-match feature frame ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def build_feature_frame(files: list) -> pd.DataFrame:
    """Build feature frame with comprehensive tennis statistics and activity tracking"""
    # Initialize tracking systems
    elo = {}
    s_elo = {"Hard": {}, "Clay": {}, "Grass": {}}
    h2h = {}
    activity_hist = {}
    player_form = defaultdict(lambda: defaultdict(list))

    rec = []

    print("üîß Processing matches and building features...")
    for fn in tqdm(files, desc="Parsing matches"):
        try:
            df = pd.read_csv(os.path.join(DATA, fn), low_memory=False, on_bad_lines="skip")
            df["tourney_date"] = df["tourney_date"].apply(parse_date)
            df = df.dropna(axis=0, how="any", subset=["tourney_date", "winner_id", "loser_id"])
            df = df[df.tourney_date.dt.year >= MIN_YR]

            # Safe conversion to integers
            df["winner_id"] = pd.to_numeric(df["winner_id"], errors='coerce')
            df["loser_id"] = pd.to_numeric(df["loser_id"], errors='coerce')
            df = df.dropna(subset=["winner_id","loser_id"])
            df = df.astype({"winner_id":int,"loser_id":int})
            df = df.sort_values(["tourney_date","match_num"] if "match_num" in df.columns else ["tourney_date"])

            for _, r in df.iterrows():
                w, l = r.winner_id, r.loser_id
                current_date = r.tourney_date

                # Initialize tracking for new players
                for p in (w, l):
                    elo.setdefault(p, 1500)
                    for s in s_elo:
                        s_elo[s].setdefault(p, 1500)
                    activity_hist.setdefault(p, {
                        "last_match": None,
                        "match_dates": [],
                        "recent_results": [],
                        "surface_matches": {"Hard": 0, "Clay": 0, "Grass": 0}
                    })

                # Calculate activity metrics BEFORE the match
                w_activity = activity_hist[w]
                l_activity = activity_hist[l]

                w_days_since = (current_date - w_activity["last_match"]).days if w_activity["last_match"] else 180
                l_days_since = (current_date - l_activity["last_match"]).days if l_activity["last_match"] else 180

                w_matches_90d = len([d for d in w_activity["match_dates"] if (current_date - d).days <= 90])
                l_matches_90d = len([d for d in l_activity["match_dates"] if (current_date - d).days <= 90])

                surface = r.get("surface", "Hard") or "Hard"
                if surface not in s_elo:
                    surface = "Hard"

                w_surface_matches = len([d for d in w_activity["match_dates"] if (current_date - d).days <= 365])
                l_surface_matches = len([d for d in l_activity["match_dates"] if (current_date - d).days <= 365])

                w_recent_form = np.mean(w_activity["recent_results"][-10:]) if w_activity["recent_results"] else 0.5
                l_recent_form = np.mean(l_activity["recent_results"][-10:]) if l_activity["recent_results"] else 0.5

                w_surface_form = np.mean(player_form[w][surface][-15:]) if player_form[w][surface] else 0.5
                l_surface_form = np.mean(player_form[l][surface][-15:]) if player_form[l][surface] else 0.5

                # Get ratings BEFORE the match
                w_se, l_se = s_elo[surface][w], s_elo[surface][l]

                pair = tuple(sorted([w, l]))
                h2h.setdefault(pair, [0, 0])
                pre_h2h = h2h[pair][0] - h2h[pair][1] if pair[0] == w else h2h[pair][1] - h2h[pair][0]

                # Store match record with PRE-MATCH information only
                rec.append(dict(
                    date=current_date, surface=surface,
                    tlevel=r.get("tourney_level","A"), draw=r.get("draw_size",32),
                    winner_id=w, loser_id=l,
                    w_e=elo[w], l_e=elo[l],
                    w_se=w_se, l_se=l_se,
                    h2h=pre_h2h,
                    w_rank=r.get("winner_rank",100), l_rank=r.get("loser_rank",100),
                    w_pts=r.get("winner_rank_points",1000), l_pts=r.get("loser_rank_points",1000),
                    w_age=r.get("winner_age",25), l_age=r.get("loser_age",25),
                    w_ht=r.get("winner_ht",180), l_ht=r.get("loser_ht",180),
                    w_hand=r.get("winner_hand","R"), l_hand=r.get("loser_hand","R"),
                    w_form=w_surface_form, l_form=l_surface_form,
                    w_days_since=w_days_since,
                    l_days_since=l_days_since,
                    w_matches_90d=w_matches_90d,
                    l_matches_90d=l_matches_90d,
                    w_surface_matches=w_surface_matches,
                    l_surface_matches=l_surface_matches,
                    w_recent_form=w_recent_form,
                    l_recent_form=l_recent_form,
                ))

                # Update ratings and activity AFTER recording pre-match state
                k = 32
                expected = 1/(1+10**((elo[l]-elo[w])/400))
                elo[w] += k*(1-expected); elo[l] -= k*(1-expected)

                e_surface = s_elo[surface]
                expected_s = 1/(1+10**((e_surface[l]-e_surface[w])/400))
                e_surface[w] += k*(1-expected_s); e_surface[l] -= k*(1-expected_s)

                h2h[pair][0 if pair[0]==w else 1] += 1

                # Update activity tracking
                for p, result in [(w, 1), (l, 0)]:
                    activity_hist[p]["last_match"] = current_date
                    activity_hist[p]["match_dates"].append(current_date)
                    activity_hist[p]["recent_results"].append(result)
                    activity_hist[p]["surface_matches"][surface] += 1
                    player_form[p][surface].append(result)

                    # Keep only last 50 matches for memory efficiency
                    if len(activity_hist[p]["match_dates"]) > 50:
                        activity_hist[p]["match_dates"] = activity_hist[p]["match_dates"][-50:]
                        activity_hist[p]["recent_results"] = activity_hist[p]["recent_results"][-50:]

                    if len(player_form[p][surface]) > 50:
                        player_form[p][surface] = player_form[p][surface][-50:]

        except Exception as e:
            print(f"Error processing {fn}: {e}")
            continue

    return pd.DataFrame(rec)

# ‚ïî‚ïê‚ïê 5. Build feature matrix & target variable ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def build_X_y(df: pd.DataFrame) -> tuple:
    """Build feature matrix with comprehensive tennis features using activity tracking"""
    le = LabelEncoder()
    surf_enc = le.fit_transform(df.surface.fillna("Hard"))

    # Create random assignment for player perspective (fixes target variable issue)
    np.random.seed(42)
    p1 = np.random.rand(len(df)) > 0.5
    y = p1.astype(int)  # Target: 1 if assigned "player 1" was the actual winner

    # Build comprehensive feature matrix
    X = pd.DataFrame({
        # Core rating differences
        "elo_diff": np.where(p1, df.w_e - df.l_e, df.l_e - df.w_e),
        "surf_elo_diff": np.where(p1, df.w_se - df.l_se, df.l_se - df.w_se),

        # Form and momentum
        "form_diff": np.where(p1, df.w_form - df.l_form, df.l_form - df.w_form),
        "recent_form_diff": np.where(p1, df.w_recent_form - df.l_recent_form,
                                   df.l_recent_form - df.w_recent_form),

        # Head-to-head and ranking
        "h2h_adv": np.where(p1, df.h2h, -df.h2h),
        "rank_diff": np.where(p1, df.l_rank - df.w_rank, df.w_rank - df.l_rank),
        "rank_pts_diff": np.where(p1, df.w_pts - df.l_pts, df.l_pts - df.w_pts),

        # Physical and style characteristics
        "age_diff": np.where(p1, df.w_age - df.l_age, df.l_age - df.w_age),
        "height_diff": np.where(p1, df.w_ht - df.l_ht, df.l_ht - df.w_ht),
        "hand_adv": np.where(
            p1,
            ((df.w_hand == 'L') & (df.l_hand == 'R')).astype(int) -
            ((df.w_hand == 'R') & (df.l_hand == 'L')).astype(int),
            ((df.l_hand == 'L') & (df.w_hand == 'R')).astype(int) -
            ((df.l_hand == 'R') & (df.w_hand == 'L')).astype(int)),

        # Tournament context
        "is_masters": (df.tlevel == 'M').astype(int),
        "is_grand_slam": (df.tlevel == 'G').astype(int),
        "draw_size_log": np.log2(df.draw),
        "surface_encoded": surf_enc,

        # Advanced rating features
        "elo_momentum": np.where(p1,
                                (df.w_e - 1500) - (df.l_e - 1500),
                                (df.l_e - 1500) - (df.w_e - 1500)),

        # Activity and freshness features (kept for Tennis Abstract proxy)
        "activity_diff": np.where(p1, df.w_matches_90d - df.l_matches_90d,
                                 df.l_matches_90d - df.w_matches_90d),
        "freshness_penalty": np.where(p1,
            np.log1p(df.w_days_since) - np.log1p(df.l_days_since),
            np.log1p(df.l_days_since) - np.log1p(df.w_days_since)),
        "rust_factor": np.maximum(df.w_days_since, df.l_days_since) / 30,
        "surface_experience_diff": np.where(p1,
            df.w_surface_matches - df.l_surface_matches,
            df.l_surface_matches - df.w_surface_matches),

        # Form confidence features
        "form_confidence": np.where(p1,
            df.w_recent_form - df.l_recent_form,
            df.l_recent_form - df.w_recent_form),

        # Ranking volatility
        "ranking_volatility": np.where(p1,
            np.abs(df.w_rank - 50) - np.abs(df.l_rank - 50),
            np.abs(df.l_rank - 50) - np.abs(df.w_rank - 50))
    }).fillna(0)

    return X, y, df.date, le

# ‚ïî‚ïê‚ïê 6. Train & evaluate XGBoost with GPU support ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def train_evaluate_with_gpu(X: pd.DataFrame, y: pd.Series, dates: pd.Series) -> tuple:
    """Train XGBoost model with GPU acceleration and proper parameter handling"""
    split = dates.quantile(0.8)
    train_mask = dates < split

    # Check GPU availability
    gpu_available = check_gpu_availability()

    # Configure XGBoost parameters based on GPU availability
    if gpu_available:
        params = {
            "objective": "binary:logistic",
            "eval_metric": "logloss",
            "n_estimators": 2000,
            "learning_rate": 0.02,
            "max_depth": 8,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "reg_alpha": 0.1,
            "reg_lambda": 0.1,
            "random_state": 42,
            "tree_method": 'gpu_hist',
            "predictor": 'gpu_predictor',
            "gpu_id": 0,
            "early_stopping_rounds": 100,
            "enable_categorical": False
        }
        print("üöÄ Training with GPU acceleration")
    else:
        params = {
            "objective": "binary:logistic",
            "eval_metric": "logloss",
            "n_estimators": 1500,
            "learning_rate": 0.03,
            "max_depth": 6,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "reg_alpha": 0.1,
            "reg_lambda": 0.1,
            "random_state": 42,
            "tree_method": 'hist',
            "early_stopping_rounds": 100,
            "enable_categorical": False
        }
        print("üñ•Ô∏è Training with CPU")

    model = xgb.XGBClassifier(**params)

    print(f"üìä Training on {train_mask.sum():,} samples...")
    model.fit(X[train_mask], y[train_mask],
              eval_set=[(X[~train_mask], y[~train_mask])],
              verbose=False)

    # Evaluate model performance
    pred = model.predict(X[~train_mask])
    proba = model.predict_proba(X[~train_mask])[:, 1]
    acc = accuracy_score(y[~train_mask], pred)
    auc = roc_auc_score(y[~train_mask], proba)

    device = "GPU" if gpu_available else "CPU"
    print(f"\nüéØ {device} TRAINING RESULTS:")
    print(f"   Accuracy: {acc:.3%}")
    print(f"   AUC: {auc:.3f}")
    print(f"   Training samples: {train_mask.sum():,}")
    print(f"   Validation samples: {(~train_mask).sum():,}")

    # Feature importance analysis
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nüèÜ TOP 20 MOST IMPORTANT FEATURES:")
    print(feature_importance.head(20).to_string(index=False))

    return model, feature_importance

# ‚ïî‚ïê‚ïê 7. Main execution pipeline ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
def main() -> None:
    """Main execution pipeline"""
    print("üéæ TENNIS ATP MATCH-WINNER MODEL v6.2 (Tennis Abstract Compatible)")
    print("üöÄ Optimized for Tennis Abstract data integration")
    print("=" * 60)

    # Step 1: Download data
    csv_files = download_csvs()

    # Step 2: Build feature frame
    frame = build_feature_frame(csv_files)
    print(f"‚úÖ Created feature frame with {len(frame):,} matches")

    # Add this save step:
    print("üíæ Saving feature frame for backtesting...")
    frame.to_pickle("tennis_feature_frame.pkl")
    print("‚úÖ Feature frame saved successfully")

    # Step 3: Build feature matrix
    print("üßÆ Building feature matrix...")
    X, y, dates, encoder = build_X_y(frame)
    print(f"‚úÖ Feature matrix: {X.shape[0]:,} samples, {X.shape[1]} features")

    # Step 4: Train model
    print("ü§ñ Training model...")
    model, feature_importance = train_evaluate_with_gpu(X, y, dates)

    # Step 5: Save model
    print("üíæ Saving model...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    model_output_path = f"tennis_model_tennis_abstract_{timestamp}.json"
    encoder_output_path = f"surface_encoder_tennis_abstract_{timestamp}.pkl"
    importance_output_path = f"feature_importance_tennis_abstract_{timestamp}.csv"

    model.save_model(model_output_path)
    pickle.dump(encoder, open(encoder_output_path, "wb"))
    feature_importance.to_csv(importance_output_path, index=False)

    print(f"\nüéæ TENNIS ABSTRACT COMPATIBLE MODEL FINISHED!")
    print(f"üìä Features: {len(X.columns)}")
    print(f"üíæ Model saved: {model_output_path}")
    print(f"üíæ Encoder saved: {encoder_output_path}")
    print(f"üíæ Feature importance saved: {importance_output_path}")
    print("=" * 60)
    print("üèÜ Ready for production use!")

# Move the interactive prediction cell under the __main__ guard
if __name__ == "__main__":
    main()

    # @title INTERACTIVE TENNIS MATCH PREDICTION CELL FOR COLAB
    ### ======================================================= ###
    ###   INTERACTIVE TENNIS MATCH PREDICTION CELL FOR COLAB    ###
    ###        (Updated for Glicko Components)                ###
    ### ======================================================= ###

    import pandas as pd
    import xgboost as xgb
    import pickle
    import json
    import os

    # --- 1. Configuration: Use latest model/encoder automatically ---
    def find_latest_files() -> tuple:
        """Finds the most recently created model and encoder files in the current directory."""
        models = sorted([f for f in os.listdir() if f.startswith('tennis_model_tennis_abstract') and f.endswith('.json')])
        encoders = sorted([f for f in os.listdir() if f.startswith('surface_encoder_tennis_abstract') and f.endswith('.pkl')])
        if not models or not encoders:
            return None, None
        return models[-1], encoders[-1]

    model_path, encoder_path = find_latest_files()

    # --- 2. Helper Functions (with the fix) ---
    def load_model_and_encoder(model_path: str, encoder_path: str) -> tuple:
        """Loads the trained XGBoost model and the surface encoder from disk."""
        print(f"üîÑ Loading model from: {model_path}")
        model = xgb.XGBClassifier()
        model.load_model(model_path)
        print("‚úÖ Model loaded successfully.")

        print(f"üîÑ Loading encoder from: {encoder_path}")
        with open(encoder_path, 'rb') as f:
            encoder = pickle.load(f)
        print("‚úÖ Encoder loaded successfully.")

        return model, encoder

    def predict_match(model: xgb.XGBClassifier, input_data: dict) -> dict:
        """Predicts the outcome of a tennis match from the structured JSON input."""
        features = input_data["features"]
        context = input_data["match_context"]
        p1_name = context["player_1"]

        input_df = pd.DataFrame([features])
        model_feature_names = model.get_booster().feature_names
        input_df = input_df[model_feature_names]

        win_prob_p1 = model.predict_proba(input_df)[0][1]

        if win_prob_p1 >= 0.5:
            favorite_player = context["player_1"]
            predicted_probability = win_prob_p1
        else:
            favorite_player = context["player_2"]
            predicted_probability = 1 - win_prob_p1

        result = {
            "predicted_win_probability": round(float(predicted_probability), 4),
            "favorite_player": favorite_player
        }
        return result

    # --- 3. Main Interactive Execution ---
    EXAMPLE_JSON_STRING = """
    {
      "match_context": {
        "player_1": "Carlos Alcaraz",
        "player_2": "Jannik Sinner",
        "surface": "Grass",
        "tournament_level": "Unknown",
        "match_id": "alcaraz_vs_sinner_grass_simulation"
      },
      "features": {
        "elo_diff": 38, "surf_elo_diff": 173, "rank_diff": 1, "rank_pts_diff": -1130,
        "ranking_volatility": -0.12, "form_confidence": 0.18, "freshness_penalty": -0.05,
        "age_diff": 1, "is_grand_slam": 0, "h2h_adv": 0.56, "elo_momentum": 15.2,
        "activity_diff": -0.08, "rust_factor": 0.02, "form_diff": 0.18, "is_masters": 0,
        "surface_encoded": 2, "hand_adv": 0, "surface_experience_diff": 8, "recent_form_diff": 0.22,
        "height_diff": 0, "draw_size_log": 4.09
      }
    }
    """

    try:
        print("--- MODEL SETUP ---")
        if not model_path or not encoder_path:
            raise FileNotFoundError("Could not find model/encoder files.")

        tennis_model, surface_encoder = load_model_and_encoder(model_path, encoder_path)
        print("-" * 20)

        print("\nüéæ TENNIS PREDICTOR IS READY üéæ")
        print("Instructions:")
        print("1. Prepare your match data in the JSON format below.")
        print("2. Paste the entire JSON object into the input box and press Enter.")
        print("3. To finish, type 'exit' and press Enter.")
        print("\n--- JSON TEMPLATE (you can copy this) ---")
        print(EXAMPLE_JSON_STRING)
        print("-------------------------------------------\n")

        while True:
            print("\nüëá Paste your match data JSON here and press Enter (or type 'exit' to quit):")
            user_input_str = input()

            if user_input_str.strip().lower() == 'exit':
                print("üëã Exiting predictor. Goodbye!")
                break

            if not user_input_str.strip():
                print("‚ö†Ô∏è Input is empty. Please paste the JSON data or type 'exit'.")
                continue

            try:
                input_data = json.loads(user_input_str)
                prediction_result = predict_match(tennis_model, input_data)
                print("\n" + "="*50)
                print("MATCH CONTEXT")
                print(f"  Player 1: {input_data['match_context']['player_1']}")
                print(f"  Player 2: {input_data['match_context']['player_2']}")
                print(f"  Surface: {input_data['match_context']['surface']}")
                print("="*50)
                print("\nüèÜ MODEL PREDICTION OUTPUT üèÜ")
                print(json.dumps(prediction_result, indent=2))
                print("="*50)
            except json.JSONDecodeError:
                print("\n‚ùå ERROR: Invalid JSON format. Please check your pasted text.")
                print("Common mistakes include missing commas, brackets {}, or quotes \"\".")
            except KeyError as e:
                print(f"\n‚ùå ERROR: The provided JSON is missing a required key: {e}")
                print("Please ensure 'match_context' and 'features' keys are present.")
            except Exception as e:
                print(f"\n‚ùå An unexpected error occurred: {e}")
    except FileNotFoundError:
        print("\n" + "!"*50)
        print("üî• ERROR: MODEL OR ENCODER FILE NOT FOUND! üî•")
        print("Please make sure these files exist in your Colab session directory.")
        print("You may need to run the training cell again.")
        print("!"*50)